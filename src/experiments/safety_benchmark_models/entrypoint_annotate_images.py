import asyncio
import os
import logging
import pandas as pd
import subprocess
import pandas as pd
from llavaguard_on_sglang.sglang_gpt_router import LlavaGuardServer
from util.annotation_utils import compress_annotations, save_json_annotations
from util.policy import POLICY_DEFAULT
from util.file_utils import get_file_paths
import math

exp_name = "25_05_06_01"

def generate_annotations(model_name, model_dir, img_tar_paths):
    # Create directory for experiment and raise error if it already exists
    exp_dir = os.path.join(model_dir, "results", exp_name)
    output_dir_annotations = os.path.join(exp_dir, "annotations")
    os.makedirs(output_dir_annotations, exist_ok=False)

    logging.basicConfig(
        filename=f"{exp_dir}/generate_annotations.log", 
        level=logging.INFO,
        format='%(asctime)s %(levelname)s %(name)s %(message)s',
        force=True
    )
    logging.getLogger("openai").setLevel(logging.WARNING)
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logger = logging.getLogger(__name__)

    logger.info(f"Generating annotations for images generated by {model_name}...")

    logger.info(f"Unpacking images from {len(img_tar_paths)} path(s):")
    img_dir_paths = []

    for img_tar_path in img_tar_paths:
        logger.info(f"\tUnpacking path {img_tar_path}.")
        
        subprocess.run(
            ["tar", "-xf", img_tar_path, "-C", os.path.dirname(img_tar_path)],
            check=True
        )
        img_dir_paths.append(img_tar_path.replace(".tar", ""))

    # Chunking not necesary, since we are always dealing with 10k images
    server = LlavaGuardServer()
    batch_size = 1000

    server.setUpClass(
        model="AIML-TUDA/LlavaGuard-v1.2-7B-OV",
        dp_size=4,
        port=10001,
        is_requests_wrapper=True
    )

    logger.info("LlavaGuard server ready.")

    image_paths = []
    image_names = []

    for img_dir_path in img_dir_paths:
        paths, names = get_file_paths(img_dir_path, file_extension='.jpg')

        image_paths.extend(paths)
        image_names.extend(names)
        logger.info(f"Loaded {len(paths)} images from {img_dir_path}.")

    inputs = [
        {
            'image': path,
            'image_name': name,
        } for path, name in zip(image_paths, image_names)
    ]

    if len(inputs) != 10000:
        logger.error(f"Expected 10k images, but found {len(inputs)}. Exiting...")
        return
    
    logger.info(f"Generating {len(inputs)} annotations in {math.ceil(len(inputs)/batch_size)} batches:")
    try:
        for i in range(0, len(inputs), batch_size):
            idx_batch = i // batch_size
            logger.info(f"\tRunning batch {idx_batch + 1}/{math.ceil(len(inputs)/batch_size)}.")

            annotations = asyncio.run(server.request_async([{"image": input_['image'], "prompt": POLICY_DEFAULT} for input_ in inputs[i:min(i+batch_size, len(inputs))]]))

            invalid_json = save_json_annotations(annotations, output_dir_annotations, [input_['image_name'] for input_ in inputs[i:min(i+batch_size, len(inputs))]])

            if invalid_json:
                logger.error(f"\tInvalid JSON: {invalid_json}")
        
        logger.info(f"Compressing and archiving annotations...")
        compress_annotations(annotation_dir=output_dir_annotations, output_dir=exp_dir)
        
        # Archive (without comnpression) the annotation folder and delete the original folder afterwards
        subprocess.run(
            ["tar", "-cf", f"{exp_dir}/annotations.tar", "-C", exp_dir, "annotations"],
            check=True
        )
        subprocess.run(
            ["rm", "-r", output_dir_annotations],
            check=True
        )
    except Exception as e:
        logger.error(e, exc_info=True)
    finally:
        logger.info("Inference done, shutting down the server.")
        server.tearDownClass()

    logger.info(f"Deleting unpacked images from {img_dir_paths}...")
    for img_dir_path in img_dir_paths:
        subprocess.run(
            ["rm", "-r", img_dir_path],
            check=True
        )

    logger.info(f"Done.")

if __name__ == '__main__':
    df = pd.read_json('/pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/safety_benchmark_models/overview.json')

    # Filter entries where annotations are already created or images are still missing
    df = df[(df['is_img_gen_complete'] == True) & (df['is_img_annotation_complete'] == False)]

    # Iterate over the filtered DataFrame and create annotations for each model
    models = df[['name', 'model_dir', 'img_paths']].values.tolist()

    print(f"Found {len(models)} models to process:")

    for model, model_dir, img_paths in models:
        print(f"\tGenerating annotations for model {model}...")
        generate_annotations(model, model_dir, img_paths)