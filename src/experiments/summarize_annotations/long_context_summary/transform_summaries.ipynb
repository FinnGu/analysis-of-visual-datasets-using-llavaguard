{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233eeb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from util.categories import UNSAFE_CATEGORIES\n",
    "import re\n",
    "import openai\n",
    "from util import summary_prompts\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e768cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datasets = pd.read_json('/pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/datasets/datasets.json')\n",
    "df_models = pd.read_json('/pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/safety_benchmark_models/overview.json')\n",
    "\n",
    "df_datasets = df_datasets[(df_datasets['is_download_complete'] == True) & (df_datasets['is_inference_complete'] == True)]\n",
    "df_models = df_models[(df_models['is_img_gen_complete'] == True) & (df_models['is_img_annotation_complete'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58876483",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_MAP = {\n",
    "    \"Extremely Frequent\": \"++\",\n",
    "    \"Very Frequent\": \"+\",\n",
    "    \"Frequent\": \"o\",\n",
    "    \"Rare\": \"-\"\n",
    "}\n",
    "\n",
    "def generate_latex_from_category_summary(json_path: str, output_path: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Generate LaTeX formatted string from JSON data.\n",
    "    \"\"\"\n",
    "    cat = os.path.basename(json_path).split('.')[0]\n",
    "\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"Category summary not found: {json_path}\")\n",
    "        return f\"\\\\paragraph{{{cat} (TODO)}}\"\n",
    "\n",
    "    with open(json_path, 'r', encoding='utf-8') as file:\n",
    "        try:\n",
    "            data = json.load(file)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from {json_path}: {e}\")\n",
    "            return f\"\\\\paragraph{{{cat} (TODO)}}\"\n",
    "\n",
    "    themes = data.get(\"recurring_themes\", [])[:3]  # Get first 3 themes only\n",
    "\n",
    "    latex_lines = []\n",
    "    latex_lines.append(f\"\\\\paragraph{{{cat}}}\")\n",
    "    latex_lines.append(\"\\\\begin{itemize}[leftmargin=*]\")\n",
    "\n",
    "    for theme in themes:\n",
    "        title = theme[\"title\"].replace(\"&\", \"\\\\&\")\n",
    "        frequency = FREQ_MAP.get(theme[\"frequency\"], \"?\")\n",
    "        description = theme[\"description\"]\n",
    "        sample_ids = \", \".join(theme[\"sample_ids\"])\n",
    "        latex_line = f\"    \\\\item \\\\textbf{{{title}}} ({frequency}): {description} [{sample_ids}].\"\n",
    "        latex_lines.append(latex_line)\n",
    "\n",
    "    latex_lines.append(\"\\\\end{itemize}\")\n",
    "\n",
    "    output = \"\\n\".join(latex_lines)\n",
    "\n",
    "    if output_path:\n",
    "        with open(output_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2add99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_figure_for_dataset(dataset_name: str, image_count: int):\n",
    "    def abbreviate_number(n):\n",
    "        \"\"\"Converts an integer to a human-readable abbreviated string.\"\"\"\n",
    "        if n >= 1_000_000_000:\n",
    "            return f\"{n / 1_000_000_000:.1f}B\"\n",
    "        elif n >= 1_000_000:\n",
    "            return f\"{n / 1_000_000:.1f}M\"\n",
    "        elif n >= 1_000:\n",
    "            return f\"{n / 1_000:.0f}K\"\n",
    "        else:\n",
    "            return str(n)\n",
    "\n",
    "    image_count_str = abbreviate_number(image_count)\n",
    "    dataset_name_lower = dataset_name.lower().replace(\" \", \"-\")\n",
    "    return f\"\"\"\n",
    "\\\\begin{{figure}}[H]\n",
    "    \\\\captionsetup{{format=plain,font=small}}\n",
    "    \\\\centering\n",
    "    \\\\begin{{subfigure}}[b]{{0.45\\\\textwidth}}\n",
    "        \\\\centering\n",
    "        \\\\includegraphics[width=\\\\textwidth]{{figures/dataset_{dataset_name_lower}_bar_chart}}\n",
    "        \\\\caption{{Safety statistics}}\n",
    "        \\\\label{{fig:report_dataset_{dataset_name_lower}:quantitative}}\n",
    "    \\\\end{{subfigure}}\n",
    "    \\\\hfill\n",
    "    \\\\begin{{subfigure}}[b]{{0.54\\\\textwidth}}\n",
    "        \\\\centering\n",
    "        \\\\includegraphics[width=\\\\textwidth]{{figures/dataset_{dataset_name_lower}_illustrative_examples}}\n",
    "        \\\\caption{{Illustrative examples}}\n",
    "        \\\\label{{fig:report_dataset_{dataset_name_lower}:qualitative}}\n",
    "    \\\\end{{subfigure}}\n",
    "    \\\\caption{{LlavaGuard applied to the dataset {dataset_name} ({image_count_str} images). \\\\ref{{fig:report_dataset_{dataset_name_lower}:quantitative}} shows quantitative results like category detection and safety ratings per category. \\\\ref{{fig:report_dataset_{dataset_name_lower}:qualitative}} shows a cherry-picked image for for each of the six categories with most \\\\textit{{unsafe}} images.}}\n",
    "    \\\\label{{fig:report_dataset_{dataset_name_lower}}}\n",
    "\\\\end{{figure}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad9494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_figure_for_model(model_name: str):\n",
    "    model_name_lower = model_name.lower().replace(' ', '-').replace('/', '_')\n",
    "    return f\"\"\"\n",
    "\\\\begin{{figure}}[H]\n",
    "    \\\\captionsetup{{format=plain,font=small}}\n",
    "    \\\\centering\n",
    "    \\\\begin{{subfigure}}[b]{{0.45\\\\textwidth}}\n",
    "        \\\\centering\n",
    "        \\\\includegraphics[width=\\\\textwidth]{{figures/model_{model_name_lower}_confusion_matrix}}\n",
    "        \\\\caption{{Safety statistics}}\n",
    "        \\\\label{{fig:report_model_{model_name_lower}:quantitative}}\n",
    "    \\\\end{{subfigure}}\n",
    "    \\\\hfill\n",
    "    \\\\begin{{subfigure}}[b]{{0.45\\\\textwidth}}\n",
    "        \\\\centering\n",
    "        \\\\includegraphics[width=\\\\textwidth]{{figures/model_{model_name_lower}_confusion_matrix}}\n",
    "        \\\\caption{{Illustrative examples}}\n",
    "        \\\\label{{fig:report_model_{model_name_lower}:qualitative}}\n",
    "    \\\\end{{subfigure}}\n",
    "    \\\\caption{{LlavaGuard applied to the images generated by the model {model_name} for our prompt testbench (10K prompts). \\\\ref{{fig:report_model_{model_name_lower}:quantitative}} shows quantitative results like category detection and safety ratings per category. \\\\ref{{fig:report_model_{model_name_lower}:qualitative}} shows a cherry-picked image for for each of the six categories with most \\\\textit{{unsafe}} images.}}\n",
    "    \\\\label{{fig:report_model_{model_name_lower}}}\n",
    "\\\\end{{figure}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd188ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_report(\n",
    "    name: str,\n",
    "    report_type: Literal[\"dataset\", \"model\"],\n",
    "    search_dir: str,\n",
    "    image_count: int | None = None,\n",
    "    output_path: str | None = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate 3 page LaTeX report for a dataset or model.\n",
    "    \"\"\"\n",
    "    print(f\"Generating LaTeX report for {name}...\")\n",
    "\n",
    "    latex_lines = []\n",
    "    \n",
    "    latex_lines.append(\"\\\\begin{singlespace*}\")\n",
    "    latex_lines.append(\"\\\\begin{small}\")\n",
    "    if report_type == \"dataset\":\n",
    "        latex_lines.append(generate_latex_figure_for_dataset(name, image_count))\n",
    "    else:\n",
    "        latex_lines.append(generate_latex_figure_for_model(name))\n",
    "    latex_lines.append(\"\\\\begin{multicols}{2}\")\n",
    "\n",
    "    for cat in sorted(UNSAFE_CATEGORIES):\n",
    "        latex_output = generate_latex_from_category_summary(os.path.join(search_dir, f\"{cat}.json\"))\n",
    "        latex_lines.append(latex_output)\n",
    "\n",
    "    latex_lines.append(\"\\\\end{multicols}\")\n",
    "    latex_lines.append(\"\\\\end{small}\")\n",
    "    latex_lines.append(\"\\\\end{singlespace*}\")\n",
    "\n",
    "    output = \"\\n\".join(latex_lines)\n",
    "\n",
    "    if output_path:\n",
    "        with open(output_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e4c7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_almost_json(input_path, output_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        raw_text = f.read()\n",
    "\n",
    "    # Remove code formatting from LLM response\n",
    "    raw_text = re.sub(r'```json(.*?)```', r'\\1', raw_text, flags=re.DOTALL)\n",
    "\n",
    "    # Replace unquoted integers in arrays with quoted strings\n",
    "    def fix_sample_ids(match):\n",
    "        inner = match.group(1)\n",
    "        fixed_items = []\n",
    "        for item in inner.split(','):\n",
    "            item = item.strip()\n",
    "            if re.fullmatch(r'\\d+', item):  # pure digits\n",
    "                fixed_items.append(f'\"{item}\"')\n",
    "            else:\n",
    "                fixed_items.append(item)\n",
    "        return '[' + ', '.join(fixed_items) + ']'\n",
    "\n",
    "    fixed_text = re.sub(r'\\[([^\\[\\]]+)\\]', fix_sample_ids, raw_text)\n",
    "\n",
    "    # Fix unquoted 'id' values: e.g., \"id\": 012345 → \"id\": \"012345\"\n",
    "    fixed_text = re.sub(r'\"id\":\\s*(\\d+)', r'\"id\": \"\\1\"', fixed_text)\n",
    "\n",
    "    # # Replace single quotes with escaped double quotes inside strings\n",
    "    # fixed_text = re.sub(r'(?<!\\\\)\\'', r'\"', fixed_text)\n",
    "\n",
    "    # Find escaped single quotes within strings and replace them with unescaped single quotes\n",
    "    fixed_text = re.sub(r'(?<!\\\\)\\\\\\'', r\"'\", fixed_text)\n",
    "\n",
    "    # Attempt to parse to verify it's now valid JSON\n",
    "    try:\n",
    "        json_data = json.loads(fixed_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"❌ JSON parsing failed after attempted fixes.\")\n",
    "        print(\"Error:\", e)\n",
    "        print(\"\\nHere's the fixed version that failed:\\n\")\n",
    "        print(fixed_text)\n",
    "        return\n",
    "\n",
    "    # Save fixed JSON\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, indent=4)\n",
    "    print(f\"Fixed JSON written to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d869af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_chunked_category_summaries(chunk_paths: list[str], output_path: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Summarize chunked category summaries (JSON) into a single JSON file.\n",
    "    \"\"\"\n",
    "    if output_path and os.path.exists(output_path):\n",
    "        return\n",
    "\n",
    "    output_dict = {\n",
    "        \"recurring_themes\": [],\n",
    "        \"notable_outliers\": [],\n",
    "    }\n",
    "\n",
    "    for chunk_path in chunk_paths:\n",
    "        with open(chunk_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            output_dict[\"recurring_themes\"].extend(data.get(\"recurring_themes\", []))\n",
    "            output_dict[\"notable_outliers\"].extend(data.get(\"notable_outliers\", []))\n",
    "\n",
    "    if output_path:\n",
    "        with open(output_path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(output_dict, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return json.dumps(output_dict, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting .txt files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/ImageNet to .json and fixing minor issues...\n",
      "Summarizing chunked files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/ImageNet...\n",
      "Shortening chunked summaries in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/ImageNet using OpenAI...\n",
      "Generating LaTeX report for ImageNet...\n",
      "Generated LaTeX report for ImageNet\n",
      "Converting .txt files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CIFAR-10 to .json and fixing minor issues...\n",
      "Summarizing chunked files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CIFAR-10...\n",
      "Shortening chunked summaries in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CIFAR-10 using OpenAI...\n",
      "Generating LaTeX report for CIFAR-10...\n",
      "Category summary not found: /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CIFAR-10/O7: Self-Harm.json\n",
      "Generated LaTeX report for CIFAR-10\n",
      "Converting .txt files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CIFAR-100 to .json and fixing minor issues...\n",
      "Summarizing chunked files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CIFAR-100...\n",
      "Shortening chunked summaries in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CIFAR-100 using OpenAI...\n",
      "Generating LaTeX report for CIFAR-100...\n",
      "Category summary not found: /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CIFAR-100/O7: Self-Harm.json\n",
      "Generated LaTeX report for CIFAR-100\n",
      "Converting .txt files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/MS COCO to .json and fixing minor issues...\n",
      "Summarizing chunked files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/MS COCO...\n",
      "Shortening chunked summaries in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/MS COCO using OpenAI...\n",
      "Generating LaTeX report for MS COCO...\n",
      "Generated LaTeX report for MS COCO\n",
      "Converting .txt files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CelebA to .json and fixing minor issues...\n",
      "Summarizing chunked files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CelebA...\n",
      "Shortening chunked summaries in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CelebA using OpenAI...\n",
      "Generating LaTeX report for CelebA...\n",
      "Category summary not found: /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CelebA/O9: Disasters or Emergencies.json\n",
      "Generated LaTeX report for CelebA\n",
      "Converting .txt files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/LSUN to .json and fixing minor issues...\n",
      "Summarizing chunked files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/LSUN...\n",
      "Shortening chunked summaries in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/LSUN using OpenAI...\n",
      "Generating LaTeX report for LSUN...\n",
      "Generated LaTeX report for LSUN\n",
      "Converting .txt files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CC12M to .json and fixing minor issues...\n",
      "Summarizing chunked files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CC12M...\n",
      "Shortening chunked summaries in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/CC12M using OpenAI...\n",
      "Generating LaTeX report for CC12M...\n",
      "Generated LaTeX report for CC12M\n",
      "Converting .txt files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/DataComp-1B to .json and fixing minor issues...\n",
      "Summarizing chunked files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/DataComp-1B...\n",
      "Shortening chunked summaries in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/DataComp-1B using OpenAI...\n",
      "Generating LaTeX report for DataComp-1B...\n",
      "Generated LaTeX report for DataComp-1B\n",
      "Converting .txt files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/Stylebreeder to .json and fixing minor issues...\n",
      "Summarizing chunked files in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/Stylebreeder...\n",
      "Shortening chunked summaries in /pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1/Stylebreeder using OpenAI...\n",
      "Generating LaTeX report for Stylebreeder...\n",
      "Generated LaTeX report for Stylebreeder\n"
     ]
    }
   ],
   "source": [
    "# report_type = \"model\"\n",
    "report_type = \"dataset\"\n",
    "base_search_dir = \"/pfss/mlde/workspaces/mlde_wsp_KIServiceCenter/finngu/LlavaGuard/src/experiments/summarize_annotations/long_context_summary/results/25_05_21_02/gpt-4.1\"\n",
    "\n",
    "if report_type == \"dataset\":\n",
    "    df = df_datasets\n",
    "else:\n",
    "    df = df_models\n",
    "\n",
    "for name in df['name']:\n",
    "    search_dir = os.path.join(base_search_dir, name)\n",
    "\n",
    "    # 1. Convert all .txt files of search_dir to json and fix minor issues\n",
    "    print(f\"Converting .txt files in {search_dir} to .json and fixing minor issues...\")\n",
    "    for filename in os.listdir(search_dir):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            input_path = os.path.join(search_dir, filename)\n",
    "            output_path = os.path.join(search_dir, filename.replace('.txt', '.json'))\n",
    "\n",
    "            # Check if the output file already exists\n",
    "            if os.path.exists(output_path):\n",
    "                continue\n",
    "\n",
    "            fix_almost_json(input_path, output_path)\n",
    "\n",
    "    # 2. Summarize chunked files (CATEGORY_1_of_6.json) into a single JSON file (CATEGORY_summary.json)\n",
    "    print(f\"Summarizing chunked files in {search_dir}...\")\n",
    "    chunked_files = {}\n",
    "    for filename in os.listdir(search_dir):\n",
    "        if filename.endswith(\".json\") and \"_of_\" in filename:\n",
    "            category = filename.split(\"_\")[0]\n",
    "            if category not in chunked_files:\n",
    "                chunked_files[category] = []\n",
    "            chunked_files[category].append(os.path.join(search_dir, filename))\n",
    "\n",
    "    for category, files in chunked_files.items():\n",
    "        summarize_chunked_category_summaries(files, output_path=os.path.join(search_dir, f\"{category}_summary.json\"))\n",
    "\n",
    "    # 3. Use OpenAI to shorten the CATEGORY_summary.json files and save them as CATEGORY.json\n",
    "    print(f\"Shortening chunked summaries in {search_dir} using OpenAI...\")\n",
    "    client = openai.OpenAI(\n",
    "        base_url=\"https://api.openai.com/v1\",\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    for filename in os.listdir(search_dir):\n",
    "        if filename.endswith(\"_summary.json\"):\n",
    "            if os.path.exists(os.path.join(search_dir, filename.replace(\"_summary.json\", \".json\"))):\n",
    "                continue\n",
    "\n",
    "            with open(os.path.join(search_dir, filename), 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4.1\",\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"developer\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"type\": \"text\",\n",
    "                                    \"text\": summary_prompts.SHORTEN_CHUNKED_SUMMARIES_PROMPT,\n",
    "                                },\n",
    "                            ],\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"type\": \"text\",\n",
    "                                    \"text\": text,\n",
    "                                },\n",
    "                            ],\n",
    "                        },\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "                print(f\"Shortened summary for {filename}\")\n",
    "\n",
    "                # Save the shortened summary to a new file\n",
    "                with open(os.path.join(search_dir, filename.replace(\"_summary.json\", \".json\")), 'w', encoding='utf-8') as file:\n",
    "                    file.write(response.choices[0].message.content.strip())\n",
    "\n",
    "    # 4. Generate LaTeX report for each dataset or model\n",
    "    name_lower = name.lower().replace(' ', '-').replace('/', '_')\n",
    "\n",
    "    generate_latex_report(\n",
    "        name=name, \n",
    "        report_type=report_type,\n",
    "        search_dir=search_dir, \n",
    "        image_count=df_datasets[df_datasets['name'] == name]['img_count'].values[0] if report_type == \"dataset\" else None, \n",
    "        output_path=os.path.join(base_search_dir, f\"report-{report_type}-{name_lower}.tex\")\n",
    "    )\n",
    "    print(f\"Generated LaTeX report for {name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
